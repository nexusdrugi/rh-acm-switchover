ACM 2.11+ SWITCHOVER RUNBOOK — PASSIVE (CONTINUOUS) AND ONE-TIME FULL RESTORE

Last Updated: 2025-11-12
================================================================================

RESTORE METHODS OVERVIEW
================================================================================
This runbook supports two restore strategies. Choose based on your DR design:

- METHOD 1 — Continuous Passive Restore (recommended when passive sync already running):
   Secondary hub continuously restores backups; during switchover you “activate” managed clusters by
   patching the passive restore to use the latest managed-cluster backup. Fast and minimal data movement.

- METHOD 2 — One-Time Full Restore (restore everything at once):
   Perform a single restore of credentials, resources, and managed clusters from the latest backup. Use
   when passive sync is not running or bringing up a new hub.

Tip: Steps 6–12 are POST-ACTIVATION COMMON STEPS for BOTH methods.

COMMON PREREQUISITES:
- Most recent backup completed successfully and accessible (shared S3/object storage)
- Secondary hub ACM version matches the primary hub
- OADP operator installed and DataProtectionApplication configured on both hubs
- Both hubs can access the same backup storage backend
- Required operators/addons mirrored on secondary hub
- Network connectivity from managed clusters to the secondary hub
- ALL Hive ClusterDeployments have spec.preserveOnDelete=true BEFORE switchover (mandatory safety)
- Shell: commands assume bash/Posix. On Windows use WSL/Git Bash for loops & JSONPath quoting.
- At least GitOps and ACM Observability on secondary hub will need proper secrets/configuration before switchover. Use
  external syncing mechanisms (e.g., GitOps) to ensure ArgoCD and Observability have correct access details
  post-switchover or properly label those objects to be included in the backup. Or You can label those objects with
  cluster.open-cluster-management.io/backup: cluster-activation
  so that they are included in the activation restore.




Additional prerequisites for METHOD 1:
- Secondary hub is already running continuous passive restore (restore-acm-passive-sync)
- Passive sync shows Phase="Enabled" and is up-to-date with recent backups


0. VERIFY PREREQUISITES BEFORE STARTING SWITCHOVER
================================================================================
Pre-Switchover Verification:
- Most recent backup completed successfully. Check backup status with:
  "oc get backup -n open-cluster-management-backup"
- Confirm no backups are in "InProgress" state
- Verify secondary hub has same ACM version as primary
- Confirm OADP operator installed on both hubs
- Verify DataProtectionApplication configured on both hubs
- Check access to same S3 storage location from both hubs
- Validate all operators from primary are installed on secondary
- Ensure network connectivity between managed clusters and new hub
- Nodes should be in ready state and cluster should be healthy
   - If using Method 1: Verify passive sync restore is running and up-to-date on secondary hub:
      "oc get restore restore-acm-passive-sync -n open-cluster-management-backup"
      Expected: Phase="Enabled", Message="Velero restores have run to completion..."
- Inform stakeholders of planned switchover and expected downtime

MANDATORY: Set preserveOnDelete on ALL Hive ClusterDeployments
- This MUST be done BEFORE switchover to prevent accidental cluster destruction
- Check current status:
  "oc get clusterdeployment --all-namespaces -o custom-columns=NAME:.metadata.name,NAMESPACE:.metadata.namespace,PRESERVE:.spec.preserveOnDelete"
- For ANY ClusterDeployment showing "false" or "<none>", patch it immediately:
  "oc patch clusterdeployment <cluster-deployment-name> -n <namespace> --type='merge' -p '{\"spec\":{\"preserveOnDelete\":true}}'"
- Verify all show "true" before proceeding with switchover
- WITHOUT THIS: Deleting ManagedClusters from old hub will destroy the underlying cluster infrastructure




METHOD 1: CONTINUOUS PASSIVE RESTORE (ACTIVATION PATH)
================================================================================
1. PAUSE BACKUPSCHEDULE ON PRIMARY HUB (if on 2.12+)
================================================================================
Pause the BackupSchedule resources on the current primary hub by setting paused 
property to true. This prevents new backups from being created during switchover.

Find the BackupSchedule first:
   oc get backupschedule -n open-cluster-management-backup

Command for 2.12+:
   oc patch backupschedule schedule-rhacm -n open-cluster-management-backup --type='merge' -p '{"spec":{"paused":true}}'
Verify:
   oc get backupschedule schedule-rhacm -n open-cluster-management-backup -o jsonpath='{.spec.paused}'
   # Should return: true

In 2.11 you have to delete the BackupSchedule object. So it might be good to save it first:
   oc get backupschedule schedule-rhacm  -n open-cluster-management-backup -o yaml > schedule-rhacm.yaml

Delete it (on 2.11):
   oc delete backupschedule schedule-rhacm -n open-cluster-management-backup

If needed to be restored, cleanup the status and certain metadata fields (like uid, resourceversions, managedfields, ...) and then apply it again:
oc apply -f schedule-rhacm.yaml

2. PREVENT AUTO-IMPORT ON PRIMARY HUB
================================================================================
Add the disable-auto-import annotation to ALL ManagedCluster objects on the 
primary hub. This ensures the old hub won't try to recover clusters after they 
move to the new hub.

Command for each managed cluster (except local-cluster):
   oc annotate managedcluster <managed-cluster-name> import.open-cluster-management.io/disable-auto-import=''

Batch command:
   for cluster in $(oc get managedclusters -o name | grep -v local-cluster); do
     oc annotate $cluster import.open-cluster-management.io/disable-auto-import=''
   done

Verify:
   oc get managedclusters -o custom-columns=NAME:.metadata.name,DISABLE-IMPORT:.metadata.annotations.import\\.open-cluster-management\\.io/disable-auto-import


3. SHUT DOWN THANOS COMPACTOR ON PRIMARY HUB
================================================================================
Stop the Thanos compactor to prevent write conflicts on shared object storage
while the secondary hub is being activated.

Command:
   oc scale statefulset observability-thanos-compact -n open-cluster-management-observability --replicas=0

Verify compactor is stopped:
   oc get pods -n open-cluster-management-observability | grep thanos-compact
   # Should show no resources


4. VERIFY LATEST PASSIVE RESTORE ON SECONDARY HUB (NEW STEP)
================================================================================
Before activation, ensure the secondary hub has received and restored the latest 
backup data from the primary hub.

On SECONDARY HUB, verify passive sync status:
   oc get restore restore-acm-passive-sync -n open-cluster-management-backup

Expected output should show:
   NAME                        PHASE     MESSAGE
   restore-acm-passive-sync    Enabled   Velero restores have run to completion, restore will continue to sync with new backups

Check the timestamp of the last restored backup:
   oc get restore restore-acm-passive-sync -n open-cluster-management-backup -o jsonpath='{.status.veleroCredentialsRestoreName}'
   oc get restore restore-acm-passive-sync -n open-cluster-management-backup -o jsonpath='{.status.veleroResourcesRestoreName}'

Verify these match recent backups from primary (one per backup):

for s in $(oc get backup -n open-cluster-management-backup --context mgmt1 -o json \
  | jq -r '.items[].metadata.labels["velero.io/schedule-name"]' | sort -u); do
  echo -n "$s: "
  oc get backup -n open-cluster-management-backup --context mgmt1 \
    -l velero.io/schedule-name="$s" \
    --sort-by=.metadata.creationTimestamp --no-headers | tail -n1 | awk '{print $1 " (" $2 ")"}'
done


IMPORTANT: Do not proceed until passive sync shows latest data has been restored.


5. ACTIVATE MANAGED CLUSTERS ON SECONDARY HUB (CORRECTED FOR CONTINUOUS PASSIVE RESTORE)
================================================================================
CRITICAL: Since you're using continuous passive restore, you must either DELETE 
the existing restore-acm-passive-sync and create an activation restore, OR patch 
the existing restore to trigger activation.

CHOOSE ONE OF THE FOLLOWING OPTIONS: Option A should be preferred.

OPTION A: Patch Existing Restore (SIMPLER and less error prone - In-place activation)
------------------------------------------------------------------------------
Step 5: Activate by patching veleroManagedClustersBackupName to 'latest':
   oc patch restore restore-acm-passive-sync \
     -n open-cluster-management-backup \
     --type='merge' \
     -p '{"spec":{"veleroManagedClustersBackupName":"latest"}}'

Monitor status:
   # Watch for transition to Finished state
   oc get restore restore-acm-passive-sync -n open-cluster-management-backup -w

You should get something like:
NAME                       PHASE      MESSAGE
restore-acm-passive-sync   Finished   All Velero restores have run successfully

   # Verify activation completed
   oc describe restore restore-acm-passive-sync -n open-cluster-management-backup

NOTE: When veleroManagedClustersBackupName changes to 'latest', managed clusters 
are activated and the restore transitions to "Finished" status. The continuous 
sync (syncRestoreWithNewBackups) is automatically disabled upon activation.

Or

OPTION B: Delete & Create Activation Restore
------------------------------------------------------------------------------
Step 5a: Verify current passive sync restore status:
   oc get restore restore-acm-passive-sync -n open-cluster-management-backup

Step 5b: Delete the existing passive sync restore:
   oc delete restore restore-acm-passive-sync -n open-cluster-management-backup

Step 5c: Create activation restore manifest (restore-acm-activate.yaml):
   apiVersion: cluster.open-cluster-management.io/v1beta1
   kind: Restore
   metadata:
     name: restore-acm-activate
     namespace: open-cluster-management-backup
   spec:
     cleanupBeforeRestore: CleanupRestored
     veleroManagedClustersBackupName: latest  # This activates managed clusters
     veleroCredentialsBackupName: skip        # Already restored by passive sync
     veleroResourcesBackupName: skip          # Already restored by passive sync

Step 5d: Apply the activation restore:
   oc apply -f restore-acm-activate.yaml

Step 5e: Monitor activation progress:
   # Watch restore status (Ctrl+C to exit)
   oc get restore restore-acm-activate -n open-cluster-management-backup -w
   
   # Check for completion
   oc get restore restore-acm-activate -n open-cluster-management-backup
   # Expected: Phase should transition to "Finished"
   
   # Check for any errors
   oc describe restore restore-acm-activate -n open-cluster-management-backup
    # Review Events section for any issues

METHOD 2: ONE-TIME FULL RESTORE (NO PRIOR PASSIVE SYNC)
================================================================================
Use when passive sync was NOT running. If the primary hub is still accessible, you may still perform steps 1–3
on the primary (pause backups, disable auto-import, stop Thanos compactor) as pre-restore safety measures.

F1. (Optional, primary reachable) Pause BackupSchedule on primary hub
      - 2.12+: oc patch backupschedule schedule-rhacm ... paused=true
      - 2.11: save YAML then delete BackupSchedule (same commands as step 1)

F2. (Optional) Prevent auto-import on primary hub (same as step 2)

F3. (Optional) Shut down Thanos compactor on primary hub (same as step 3)

F4. Create full restore on SECONDARY hub (restore-acm-full.yaml):
      apiVersion: cluster.open-cluster-management.io/v1beta1
      kind: Restore
      metadata:
         name: restore-acm-full
         namespace: open-cluster-management-backup
      spec:
         cleanupBeforeRestore: CleanupRestored
         veleroManagedClustersBackupName: latest
         veleroCredentialsBackupName: latest
         veleroResourcesBackupName: latest

      Apply & monitor:
         oc apply -f restore-acm-full.yaml
         oc get restore restore-acm-full -n open-cluster-management-backup -w
         oc describe restore restore-acm-full -n open-cluster-management-backup
      Proceed ONLY when Phase=Finished.

F5. Continue with POST-ACTIVATION COMMON STEPS below.

POST-ACTIVATION — COMMON STEPS (APPLIES TO BOTH METHODS)
================================================================================
6. VERIFY MANAGEDCLUSTERS ARE CONNECTED
================================================================================
After activation completes, verify that ManagedClusters are connecting to the 
new hub.

Check ManagedCluster status:
   oc get managedclusters -o custom-columns=NAME:.metadata.name,AVAILABLE:.status.conditions[?(@.type==\"ManagedClusterConditionAvailable\")].status

Check for clusters in Pending Import state:
   oc get managedclusters | grep "Pending Import"
   # Hive-provisioned clusters should auto-connect
   # Manually imported clusters may require reimport

For clusters stuck in Pending Import (if any):
   # The auto-import mechanism should handle this automatically
   # If issues persist after 10-15 minutes, check cluster import secrets:
   oc get secrets -n <cluster-namespace> | grep import

Verify cluster join status:
   oc get managedclusters -o custom-columns=NAME:.metadata.name,JOINED:.status.conditions[?(@.type==\"ManagedClusterJoined\")].status

All clusters should show AVAILABLE=True and JOINED=True within 5-10 minutes.


7. RESTART OBSERVATORIUM API GATEWAY PODS (NEW CRITICAL STEP)
================================================================================
CRITICAL FIX: Due to a known issue in ACM 2.12, the Observatorium API gateway 
pods contain stale tenant data after restore because Kubernetes doesn't automatically 
refresh mounted ConfigMaps. This causes metrics to be rejected and Grafana dashboards 
to show no data.

Command:
   oc rollout restart deployment observability-observatorium-api -n open-cluster-management-observability

Verify pods are restarting:
   oc get pods -n open-cluster-management-observability | grep observatorium-api

Wait for pods to be Ready (1/1):
   oc wait --for=condition=Ready pod -l app.kubernetes.io/name=observatorium-api -n open-cluster-management-observability --timeout=5m

IMPORTANT: After this restart, wait 5-10 minutes for metrics collection to resume 
and data to start appearing in Grafana dashboards.


8. VERIFY OBSERVABILITY PODS ARE RUNNING
================================================================================
Check all Observability components are deployed and running:

Command:
   oc get pods -n open-cluster-management-observability

Expected pods (all should be Running/Ready):
- observability-alertmanager-*
- observability-grafana-*
- observability-observatorium-api-*
- observability-observatorium-operator-*
- observability-rbac-query-proxy-*
- observability-thanos-compact-*
- observability-thanos-query-*
- observability-thanos-query-frontend-*
- observability-thanos-receive-default-*
- observability-thanos-rule-*
- observability-thanos-store-shard-*

Check for any pods in Error or CrashLoopBackOff state:
   oc get pods -n open-cluster-management-observability | grep -v Running | grep -v Completed


9. VERIFY METRICS COLLECTION FROM MANAGED CLUSTERS
================================================================================
Validate that metrics are flowing from managed clusters to the new hub.

Access Grafana:
   # From ACM console, navigate to: Overview > Grafana
   # Or get Grafana route:
   oc get route grafana -n open-cluster-management-observability -o jsonpath='{.spec.host}'

In Grafana:
   1. Navigate to "ACM - Clusters Overview" dashboard
   2. Verify data is visible for all expected clusters
   3. Check that metrics are recent (within last 5 minutes)
   4. Verify multiple cluster metrics are populating

Query metrics from OpenShift console (alternative verification):
   # Navigate to: Observe > Metrics
   # Query: acm_managed_cluster_info
   # Should show entries for all managed clusters

SUCCESS CRITERIA: Recent metrics (within 5-10 minutes) are visible for all 
expected managed clusters in Grafana dashboards.

TROUBLESHOOTING: If no metrics appear after 10 minutes:
   - Verify observatorium-api pods were restarted (the "RESTART OBSERVATORIUM API GATEWAY PODS" step)
   - Check metrics-collector pods on managed clusters are running
   - Verify network connectivity from managed clusters to hub


10. ENABLE BACKUPSCHEDULE ON NEW ACTIVE HUB
================================================================================
Now that the secondary hub is the active primary, enable the BackupSchedule to 
resume regular backups.

Command:
   oc patch backupschedule schedule-rhacm -n open-cluster-management-backup --type='merge' -p '{"spec":{"paused":false}}'
 Note (2.11): If you deleted the BackupSchedule in step 1, re-apply the saved YAML (after cleaning metadata)
 instead of patching:
      oc apply -f schedule-rhacm.yaml

Verify backups resume:
   oc get backupschedule schedule-rhacm -n open-cluster-management-backup
   # Phase should be "Enabled"

Check that new backups are being created:
   # Wait 5-10 minutes, then check:
   oc get backup -n open-cluster-management-backup | head -10
   # Should see new backups with recent timestamps


11. INFORM STAKEHOLDERS
================================================================================
Notify stakeholders that:
- Switchover is complete
- New hub is: <secondary-hub-name>
- All managed clusters are connected and operational
- Observability is operational (Grafana dashboards showing data)
- Backup schedule is active on new hub
- Normal operations can resume

Provide new hub cluster details and any relevant access information.


12. DECOMMISSION OLD PRIMARY HUB (OPTIONAL BUT RECOMMENDED)
================================================================================
If the old primary hub will no longer be used, remove ACM components to free 
resources and prevent confusion. This is optional but recommended for cleanup.

CRITICAL WARNING: Step 12.3 requires that ALL Hive ClusterDeployments have 
spec.preserveOnDelete=true (which should have been done in Prerequisites).
Without this, deleting ManagedClusters can DESTROY your production clusters.

Step 12.1: Delete MultiClusterObservability resource
   # Find MCO resource:
   oc get mco -A
   
   # Delete it:
   oc delete mco observability -n open-cluster-management-observability

   # Wait for Observability pods to terminate (may take 2-5 minutes):
   oc get pods -n open-cluster-management-observability

Step 12.2: Verify no Observability pods remain
   oc get pods -n open-cluster-management-observability
   # Should show: No resources found (or only terminating pods)

Step 12.3: Delete ManagedClusters from old hub (CRITICAL: READ CAREFULLY)
   PREREQUISITE CHECK: Verify ALL ClusterDeployments have preserveOnDelete=true
   oc get clusterdeployment --all-namespaces -o custom-columns=NAME:.metadata.name,PRESERVE:.spec.preserveOnDelete
   # ALL must show "true" - if any show "false" or "<none>", STOP and fix them first!

   SAFETY CHECK: Verify clusters are already managed by NEW hub
   # On NEW HUB:
   oc get managedclusters -o custom-columns=NAME:.metadata.name,AVAILABLE:.status.conditions[?(@.type==\"ManagedClusterConditionAvailable\")].status
   # All should show AVAILABLE=True on new hub before proceeding

   # On OLD HUB, check cluster status:
   oc get managedclusters
   # Clusters should be in "Unknown" state since they're connected to new hub

   # Delete ManagedClusters (keep local-cluster):
   for cluster in $(oc get managedclusters -o name | grep -v local-cluster); do
     echo "Deleting $cluster"
     oc delete $cluster
   done

   IMPORTANT: If clusters are still showing "Available" on old hub, STOP.
   This means they haven't fully moved to new hub. Wait and verify the "VERIFY MANAGEDCLUSTERS ARE CONNECTED" step succeeded.

Step 12.4: Delete MultiClusterHub resource
   # Find MCH resource:
   oc get mch -A
   
   # Delete it:
   oc delete mch multiclusterhub -n open-cluster-management

   # This process can take up to 20 minutes
   # Monitor deletion:
   oc get mch -A

Step 12.5: Verify ACM instance pods are removed
   oc get pods -n open-cluster-management
   # Operator pods may remain until operator is uninstalled
   # Application/controller pods should be gone

Note: This decommissioning does NOT delete backup data in object storage, which 
is now being used by the new hub for continued backups.


================================================================================
ROLLBACK PROCEDURE (IF NEEDED)
================================================================================
If issues occur during switchover and you need to rollback to the primary hub:

1. On SECONDARY hub (attempted new primary):
   - Delete or pause the activation restore:
     oc delete restore restore-acm-activate -n open-cluster-management-backup
     OR
     oc delete restore restore-acm-passive-sync -n open-cluster-management-backup
   Note: If you used METHOD 2 (one-time full restore), there is no passive sync restore to delete.
   Proceed to step 2 on the PRIMARY hub to allow clusters to reconnect there.

2. On PRIMARY hub (original):
   - Remove disable-auto-import annotations from ManagedClusters:
     for cluster in $(oc get managedclusters -o name | grep -v local-cluster); do
       oc annotate $cluster import.open-cluster-management.io/disable-auto-import-
     done
   
   - Restart Thanos compactor:
     oc scale statefulset observability-thanos-compact -n open-cluster-management-observability --replicas=1
   
   - Unpause BackupSchedule:
     oc patch backupschedule schedule-rhacm -n open-cluster-management-backup --type='merge' -p '{"spec":{"paused":false}}'

3. Wait for managed clusters to reconnect to primary hub (5-10 minutes)

4. Verify all clusters show Available status on primary hub


================================================================================
TROUBLESHOOTING COMMON ISSUES
================================================================================

Issue: Managed clusters stuck in "Pending Import"
Solution: Check if auto-import secrets exist:
   oc get secrets -n <cluster-namespace> | grep import
   If missing, clusters may need manual reimport

Issue: Grafana shows no data after 15 minutes
Solution:
   1. Verify the "RESTART OBSERVATORIUM API GATEWAY PODS" step was completed (restart observatorium-api pods)
   2. Check observatorium-api pod logs:
      oc logs -n open-cluster-management-observability deployment/observability-observatorium-api
   3. Check metrics-collector on managed clusters:
      oc get pods -n open-cluster-management-addon-observability

Issue: Restore stuck in "Running" state
Solution: Check Velero restore logs:
   oc get restore -n open-cluster-management-backup
   oc describe restore <restore-name> -n open-cluster-management-backup
   Check Events section for errors

Issue: Clusters showing "Unknown" on both hubs
Solution: This indicates clusters haven't connected to either hub
   - Check network connectivity from managed clusters
   - Verify klusterlet pods are running on managed clusters
   - Check for certificate issues in klusterlet logs


================================================================================
GOOD RESOURCES
================================================================================
- Official Red Hat Documentation on ACM Uninstallation:
  https://docs.redhat.com/en/documentation/red_hat_advanced_cluster_management_for_kubernetes/2.11/html/install/installing#uninstalling

- Official Red Hat Documentation on ACM Backup and Restore:
  https://docs.redhat.com/en/documentation/red_hat_advanced_cluster_management_for_kubernetes/2.11/html/business_continuity/business-cont-overview#backup-intro

- Official Red Hat Documentation on ACM 2.11 Troubleshooting:
  https://docs.redhat.com/en/documentation/red_hat_advanced_cluster_management_for_kubernetes/2.11/html/troubleshooting/index

- Red Hat Blog - ACM HA and DR Part 3 (Active-Passive Configuration):
  https://www.redhat.com/en/blog/rhacm-high-availability-and-disaster-recovery-part-3

- ACM 2.12 Release Notes (Known Issues - Observatorium stale tenant data):
  https://docs.redhat.com/en/documentation/red_hat_advanced_cluster_management_for_kubernetes/2.12/html/release_notes/acm-release-notes

- GitHub - Cluster Backup Operator:
  https://github.com/stolostron/cluster-backup-operator


================================================================================
VALIDATION NOTES
================================================================================
This runbook has been validated against:
- Red Hat ACM official documentation
- Red Hat official HA/DR blog posts
- stolostron/cluster-backup-operator source code and documentation
- OpenShift Hive documentation

Last Updated: 2025-11-12
